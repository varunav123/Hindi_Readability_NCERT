# -*- coding: utf-8 -*-
"""ncertdataexp.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1N98jVrS7Ql6wWmFwz-uw8m8QWqnyzRa1
"""

pip install readmepp

pip install indic-nlp-library

!pip install langchain huggingface_hub
!pip install llama-index-embeddings-huggingface langchain-community
!pip install llama-index-embeddings-instructor

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
import random
import math
import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler

# def excel_to_normalized_dict(file_path):
#     # Read the Excel file
#     df = pd.read_excel(file_path)

#     # Drop rows where 'word' or 'frequency' are NaN
#     df = df.dropna(subset=['word', 'frequency'])

#     # Convert frequency to numeric (if needed) and drop non-positive values
#     df['frequency'] = pd.to_numeric(df['frequency'], errors='coerce')
#     df = df[df['frequency'] > 0]  # Log transformation requires positive values

#     # Log transform the frequency
#     # df['log_frequency'] = np.log1p(df['frequency'])  # log(f + 1) to handle zero cases

#     # Min-Max normalize log frequencies
#     # scaler = MinMaxScaler()
#     # df['normalized_log_frequency'] = 1-scaler.fit_transform(df[['log_frequency']])

#     # Convert to dictionary
#     # word_freq_dict = dict(zip(df['word'], df['normalized_log_frequency']))
#     word_freq_dict = dict(zip(df['word'], df['frequency']))

#     print("Total entries:", len(df))
#     print("Unique words:", df['word'].nunique())
#     print("Dictionary size:", len(word_freq_dict))

#     return word_freq_dict

# # Example usage
# file_path = '/content/emille_word_frequency.xlsx'
# word_dict = excel_to_normalized_dict(file_path)

import re
from readmepp import ReadMe

predictor = ReadMe(lang='en')
predictorh = ReadMe(lang='hi')

class1_story=[]
class2_story=[]
class3_story=[]
class4_story=[]
class5_story=[]
class6_story=[]
class7_story=[]
class8_story=[]
class1_poem=[]
class2_poem=[]
class3_poem=[]

def store_lines_in_list_from_filename(file_path, sent_list_story, sent_list_poem):
    """
    Reads lines from a text file and stores them as sentences in a list.
    Determines the content type and line range from the file name.

    Args:
        file_path (str): Path to the text file to read.
        sentence_list (list): List to store the sentences from the file.

    Returns:
        str: The extracted file name in the format 'contenttypenumber1-number2.txt'.
    """
    file_name_pattern = re.compile(r'(story|poem)(\d+)-(\d+)\.txt')
    match = file_name_pattern.search(file_path)


    content_type = match.group(1)
    start_line = int(match.group(2))
    end_line = int(match.group(3))

    # Open the file and read the specified range of lines
    if (content_type=="story"):
      with open(file_path, 'r', encoding='utf-8') as file:
          for current_line_num, line in enumerate(file, start=1):
              if start_line <= current_line_num <= end_line:
                  sent_list_story.append(line.strip())
    else:
      with open(file_path, 'r', encoding='utf-8') as file:
          for current_line_num, line in enumerate(file, start=1):
              if start_line <= current_line_num <= end_line:
                  sent_list_poem.append(line.strip())

    return f"{content_type}number{start_line}-{end_line}.txt"

generated_file_name1s = store_lines_in_list_from_filename('/content/story1-111.txt', class1_story,class1_poem)
ratingc1s=[]
for sentence in class1_story:
  ratingc1s.append(predictorh.predict(sentence))
# for i in range(len(rating1_101)):
#   print(rating1_101[i])

generated_file_name2s = store_lines_in_list_from_filename('/content/story1-338.txt', class2_story,class2_poem)
ratingc2s=[]
for sentence in class2_story:
  ratingc2s.append(predictorh.predict(sentence))
# for i in range(len(rating1_101)):
#   print(rating1_101[i])

generated_file_name3s = store_lines_in_list_from_filename('/content/story1-202.txt', class3_story,class3_poem)
ratingc3s=[]
for sentence in class3_story:
  ratingc3s.append(predictorh.predict(sentence))
# for i in range(len(rating1_101)):
#   print(rating1_101[i])

generated_file_name4s = store_lines_in_list_from_filename('/content/story1-494.txt', class4_story,class3_poem)
ratingc4s=[]
for sentence in class4_story:
  ratingc4s.append(predictorh.predict(sentence))
# for i in range(len(rating1_101)):
#   print(rating1_101[i])

generated_file_name5s = store_lines_in_list_from_filename('/content/story1-773.txt', class5_story,class3_poem)
ratingc5s=[]
for sentence in class5_story:
  ratingc5s.append(predictorh.predict(sentence))
# for i in range(len(rating1_101)):
#   print(rating1_101[i])

generated_file_name6s = store_lines_in_list_from_filename('/content/story1-603.txt', class6_story,class3_poem)
ratingc6s=[]
for sentence in class6_story:
  ratingc6s.append(predictorh.predict(sentence))
# for i in range(len(rating1_101)):
#   print(rating1_101[i])

generated_file_name7s = store_lines_in_list_from_filename('/content/story1-784.txt', class7_story,class3_poem)
ratingc7s=[]
for sentence in class7_story:
  ratingc7s.append(predictorh.predict(sentence))
# for i in range(len(rating1_101)):
#   print(rating1_101[i])

generated_file_name8s = store_lines_in_list_from_filename('/content/story1-919.txt', class8_story,class3_poem)
ratingc8s=[]
for sentence in class8_story:
  ratingc8s.append(predictorh.predict(sentence))
# for i in range(len(rating1_101)):
#   print(rating1_101[i])

def count_jukta_akshar(word):
    """
    Counts the number of Jukta Akshars (Conjunct Consonants) in a Hindi word.

    Parameters:
    - word (str): Input Hindi word

    Returns:
    - int: Number of Jukta Akshars
    """
    # Regex to find occurrences where a consonant (excluding vowels) is followed by halant (à¥) and another consonant
    pattern = r'[\u0915-\u0939]\u094d[\u0915-\u0939]'

    # Find all matches
    jukta_akshars = re.findall(pattern, word)

    return len(jukta_akshars)

# Example Hindi words
words = ["à¤­à¤•à¥à¤¤à¤¿", "à¤®à¤¿à¤¤à¥à¤°", "à¤œà¥à¤žà¤¾à¤¨", "à¤¶à¤•à¥à¤¤à¤¿", "à¤…à¤•à¥à¤·à¤°", "à¤¸à¤®à¤", "à¤°à¤¾à¤®à¥"]  # "à¤°à¤¾à¤®à¥" has halant at the end

# Count and print the number of Jukta Akshars in each word
for word in words:
    print(f"Word: {word} â†’ Jukta Akshars: {count_jukta_akshar(word)}")

def average_word_length(sentence):
    # Split the sentence into words
    words = sentence.split()

    # Check if there are any words in the sentence
    if len(words) == 0:
        return 0  # Avoid division by zero if there are no words

    # Calculate total length of all words
    total_length = sum(len(word) for word in words)

    # Calculate average word length
    avg_length = total_length / len(words)

    return avg_length

import re
import pandas as pd

def calculate_sentence_penalty_og(sentence, penalty_type):
    # Define character groups and penalty mappings within the function
    matras_with_penalty_1 = ['u093f']
    matras_with_penalty_half = ['u0901', 'u0902', 'u093c', 'u0941', 'u0942', 'u0943', 'u0945', 'u0947', 'u0948', 'u0949', 'u094b', 'u094c', 'u094d']
    characters_with_bottom_dot = ['u0958', 'u0959', 'u095a', 'u095b', 'u095c', 'u095d', 'u095e', 'u095f']
    composite_characters_unicode = ["u0915\\\\u094d\\\\u0937", "u091c\\\\u094d\\\\u091e", "u0924\\\\u094d\\\\u0924", "u0924\\\\u094d\\\\u0930", "u0926\\\\u094d\\\\u092e", "u0926\\\\u094d\\\\u092f", "u0928\\\\u094d\\\\u0928", "u0936\\\\u094d\\\\u091a", "u0936\\\\u094d\\\\u0930", "u0936\\\\u094d\\\\u0935"]
    composite_characters = ["à¤•à¥à¤·", "à¤œà¥à¤ž", "à¤¤à¥à¤¤", "à¤¤à¥à¤°", "à¤¦à¥à¤®", "à¤¦à¥à¤¯", "à¤¨à¥à¤¨", "à¤¶à¥à¤š", "à¤¶à¥à¤°", "à¤¶à¥à¤µ"]
    all_matras = ['u0900', 'u0901', 'u0902', 'u0903', 'u0904', 'u0906', 'u0908', 'u090a', 'u090b', 'u090c', 'u090d', 'u090e', 'u0910', 'u0911', 'u0912', 'u0913', 'u0914', 'u093a', 'u093b', 'u093c', 'u093d', 'u093e', 'u093f', 'u0940', 'u0941', 'u0942', 'u0943', 'u0944', 'u0945', 'u0946', 'u0947', 'u0948', 'u0949', 'u094a', 'u094b', 'u094c', 'u094d', 'u094e', 'u094f', 'u0950', 'u0951', 'u0952', 'u0953', 'u0954', 'u0955', 'u0956', 'u0957', 'u0958', 'u0959', 'u095a', 'u095b', 'u095c', 'u095d', 'u095e', 'u095f', 'u0960', 'u0961', 'u0962', 'u0963', 'u0970', 'u0971', 'u0972', 'u0973', 'u0974', 'u0975', 'u0976', 'u0977', 'u0978', 'u0979', 'u097a', 'u097b', 'u097c', 'u097d', 'u097e', 'u097f']

    # Initialize variables
    words = sentence.split()
    total_penalty = 0
    word_penalties = []
    unicode_representations = []

    # Process each word in the sentence
    for s in words:
        penalty = 0

        # Handle composite characters
        for b in composite_characters:
            res = [m.start() for m in re.finditer(b, s)]
            for _ in res:
                s = s.replace(b, "")
                penalty += 10

        # Convert to unicode
        u = str(s.encode("unicode_escape"))
        unicode_str = u.replace("'", "")
        unicode_representations.append(unicode_str)

        # Split unicode string by "\\"
        unicode_codes = unicode_str.split("\\\\")

        # Calculate penalties based on penalty_type
        if penalty_type == "all":
            for code in unicode_codes:
                if code in all_matras:
                    penalty += 10

        elif penalty_type == "unequal":
            for i, code in enumerate(unicode_codes):
                if code in matras_with_penalty_1:
                    penalty += 10
                elif code in matras_with_penalty_half:
                    penalty += 5
                elif code in characters_with_bottom_dot:
                    penalty += 5
                if code == "u093f" and i > 2 and unicode_codes[i-2] == "u094d":
                    penalty += 10

        elif penalty_type == "equal":
            for i, code in enumerate(unicode_codes):
                if code in matras_with_penalty_1 or code in matras_with_penalty_half or code in characters_with_bottom_dot:
                    penalty += 10
                if code == "u093f" and i > 2 and unicode_codes[i-2] == "u094d":
                    penalty += 10

        # Append penalty of the word
        word_penalties.append(penalty)
        total_penalty += penalty

    # Create a DataFrame of the results
    result_df = pd.DataFrame({
        'Word': words,
        'Penalty': word_penalties,
        'Unicode Representation': unicode_representations
    })

    # Save the DataFrame to an Excel file
    result_df.to_excel("sentence_complexity_penalty.xlsx", index=False)
    if (total_penalty==0):
      total_penalty+=1
    return total_penalty

# Example usage
sentence = "à¤à¤• à¤¬à¤¾à¤° à¤•à¥€ à¤¬à¤¾à¤¤ à¤¹à¥ˆ, à¤¦à¥‹ à¤¸à¤¹à¥‡à¤²à¤¿à¤¯à¤¾à¤ à¤¥à¥€à¤‚.-. à¤à¤• à¤®à¥à¤°à¥à¤—à¥€ à¤”à¤° à¤à¤• à¤¬à¤¤à¥à¤¤à¤–à¥¤"
total_penalty = calculate_sentence_penalty_og(sentence,"all")
print(len(sentence))
print("Total Penalty:", total_penalty)
# print(df)

import matplotlib.pyplot as plt
from collections import defaultdict

def calculate_avg_penalty(sentences, integers, penalty_type):
    """
    Calculates the average penalty for sentences associated with each integer.

    Parameters:
    sentences (list of str): List of sentences to calculate penalties for.
    integers (list of int): List of integers associated with each sentence.
    penalty_type (str): Type of penalty calculation to use in `calculate_sentence_penalty`.

    Returns:
    dict: Dictionary with each unique integer and its average penalty.
    """
    # Dictionary to store penalties for each integer
    penalty_dict = defaultdict(list)

    # Calculate penalties and store them in the dictionary based on associated integer
    for sentence, integer in zip(sentences, integers):
        penalty, _ = calculate_sentence_penalty(sentence, penalty_type)  # Use the actual penalty calculation function
        penalty_dict[integer].append(penalty)

    # Calculate average penalty for each integer
    avg_penalties = {integer: sum(penalties) / len(penalties) for integer, penalties in penalty_dict.items()}

    # # Plot the results
    # plt.figure(figsize=(10, 6))
    # plt.bar(avg_penalties.keys(), avg_penalties.values(), color='skyblue')
    # plt.xlabel("Reading Level")
    # plt.ylabel("Average Penalty")
    # plt.title("Average Penalty of Sentences Associated with Each Level")
    # plt.xticks(list(avg_penalties.keys()))
    # plt.show()

    return avg_penalties

# # Example usage
# sentences = ["à¤¹à¤®à¤¾à¤°à¥‡ à¤µà¥ˆà¤œà¥à¤žà¤¾à¤¨à¤¿à¤•à¥‹à¤‚ à¤¨à¥‡ à¤šà¤‚à¤¦à¥à¤°à¤¯à¤¾à¤¨-3 à¤•à¥‹ à¤šà¤¾à¤à¤¦ à¤•à¥‡ à¤¦à¤•à¥à¤·à¤¿à¤£à¥€ à¤§à¥à¤°à¥à¤µ à¤ªà¤° à¤‰à¤¤à¤¾à¤°à¤¾ à¤¹à¥ˆà¥¤", "à¤¹à¤®à¤¾à¤°à¥‡ à¤µà¥ˆà¤œà¥à¤žà¤¾à¤¨à¤¿à¤•à¥‹à¤‚ à¤¨à¥‡ à¤šà¤‚à¤¦à¥à¤°à¤¯à¤¾à¤¨-3 à¤•à¥‹ à¤šà¤¾à¤à¤¦ à¤•à¥‡ à¤¦à¤•à¥à¤·à¤¿à¤£à¥€ à¤§à¥à¤°à¥à¤µ à¤ªà¤° à¤‰à¤¤à¤¾à¤°à¤¾ à¤¹à¥ˆà¥¤", "à¤¹à¤®à¤¾à¤°à¥‡ à¤µà¥ˆà¤œà¥à¤žà¤¾à¤¨à¤¿à¤•à¥‹à¤‚ à¤¨à¥‡ à¤šà¤‚à¤¦à¥à¤°à¤¯à¤¾à¤¨-3 à¤•à¥‹ à¤šà¤¾à¤à¤¦ à¤•à¥‡ à¤¦à¤•à¥à¤·à¤¿à¤£à¥€ à¤§à¥à¤°à¥à¤µ à¤ªà¤° à¤‰à¤¤à¤¾à¤°à¤¾ à¤¹à¥ˆà¥¤", "More sentences here."]
# integers = [1, 2, 3, 2]  # Integers associated with each sentence
# average_penalties = calculate_avg_penalty(sentences, integers)

# print("Average penalties:", average_penalties)

def calculate_avg_sentence_penalty(sentence, penalty_type):
    """
    Calculates the average penalty of a sentence by averaging the penalties of all words in the sentence.

    Parameters:
    sentence (str): The sentence for which to calculate the average penalty.
    penalty_type (str): Type of penalty calculation to use in `calculate_sentence_penalty`.

    Returns:
    float: The average penalty of the sentence.
    """
    # Split the sentence into words
    words = sentence.split()

    # Calculate penalty for each word
    word_penalties = [calculate_sentence_penalty_og(word, penalty_type) for word in words]
    total=calculate_sentence_penalty_og(sentence,penalty_type)
    # Calculate average penalty of the sentence
    avg_penalty = total/len(word_penalties)  if word_penalties else 0
    # print(word_penalties)
    # print(len(word_penalties))
    return avg_penalty

# Example usage
# sentence = "à¤à¤• à¤¬à¤¾à¤° à¤•à¥€ à¤¬à¤¾à¤¤ à¤¹à¥ˆ, à¤¦à¥‹ à¤¸à¤¹à¥‡à¤²à¤¿à¤¯à¤¾à¤ à¤¥à¥€à¤‚ à¤à¤• à¤®à¥à¤°à¥à¤—à¥€ à¤”à¤° à¤à¤• à¤¬à¤¤à¥à¤¤à¤–à¥¤"
# avg_penalty = calculate_avg_sentence_penalty(sentence)
# print("Average penalty of the sentence:", avg_penalty)
sentence="à¤à¤• à¤¬à¤¾à¤° à¤•à¥€ à¤¬à¤¾à¤¤ à¤¹à¥ˆ, à¤¦à¥‹ à¤¸à¤¹à¥‡à¤²à¤¿à¤¯à¤¾à¤ à¤¥à¥€à¤‚ à¤à¤• à¤®à¥à¤°à¥à¤—à¥€ à¤”à¤° à¤à¤• à¤¬à¤¤à¥à¤¤à¤–"
avg_penalty =calculate_avg_sentence_penalty(sentence,"equal")
print(avg_penalty)

def calculate_sentence_penalty(sentence, penalty_type):
    matras_with_penalty_1 = ['u093f']
    matras_with_penalty_half = ['u0901', 'u0902', 'u093c', 'u0941', 'u0942', 'u0943', 'u0945', 'u0947', 'u0948', 'u0949', 'u094b', 'u094c', 'u094d']
    characters_with_bottom_dot = ['u0958', 'u0959', 'u095a', 'u095b', 'u095c', 'u095d', 'u095e', 'u095f']
    composite_characters = ["à¤•à¥à¤·", "à¤œà¥à¤ž", "à¤¤à¥à¤¤", "à¤¤à¥à¤°", "à¤¦à¥à¤®", "à¤¦à¥à¤¯", "à¤¨à¥à¤¨", "à¤¶à¥à¤š", "à¤¶à¥à¤°", "à¤¶à¥à¤µ"]
    all_matras = ['u0900', 'u0901', 'u0902', 'u0903', 'u0904', 'u0906', 'u0908', 'u090a', 'u090b', 'u090c', 'u090d', 'u090e', 'u0910', 'u0911', 'u0912', 'u0913', 'u0914', 'u093a', 'u093b', 'u093c', 'u093d', 'u093e', 'u093f', 'u0940', 'u0941', 'u0942', 'u0943', 'u0944', 'u0945', 'u0946', 'u0947', 'u0948', 'u0949', 'u094a', 'u094b', 'u094c', 'u094d', 'u094e', 'u094f', 'u0950', 'u0951', 'u0952', 'u0953', 'u0954', 'u0955', 'u0956', 'u0957', 'u0958', 'u0959', 'u095a', 'u095b', 'u095c', 'u095d', 'u095e', 'u095f', 'u0960', 'u0961', 'u0962', 'u0963', 'u0970', 'u0971', 'u0972', 'u0973', 'u0974', 'u0975', 'u0976', 'u0977', 'u0978', 'u0979', 'u097a', 'u097b', 'u097c', 'u097d', 'u097e', 'u097f']

    words = sentence.split()
    word_penalties = []
    unicode_representations = []

    for s in words:
        penalty = 0

        for b in composite_characters:
            res = [m.start() for m in re.finditer(b, s)]
            for _ in res:
                s = s.replace(b, "")
                penalty += 10

        u = str(s.encode("unicode_escape"))
        unicode_str = u.replace("'", "")
        unicode_representations.append(unicode_str)
        unicode_codes = unicode_str.split("\\\\")

        if penalty_type == "all":
            for code in unicode_codes:
                if code in all_matras:
                    penalty += 10
        elif penalty_type == "unequal":
            for i, code in enumerate(unicode_codes):
                if code in matras_with_penalty_1:
                    penalty += 10
                elif code in matras_with_penalty_half:
                    penalty += 5
                elif code in characters_with_bottom_dot:
                    penalty += 5
                if code == "u093f" and i > 2 and unicode_codes[i-2] == "u094d":
                    penalty += 10
        elif penalty_type == "equal":
            for i, code in enumerate(unicode_codes):
                if code in matras_with_penalty_1 or code in matras_with_penalty_half or code in characters_with_bottom_dot:
                    penalty += 10
                if code == "u093f" and i > 2 and unicode_codes[i-2] == "u094d":
                    penalty += 10

        word_penalties.append(penalty)

    result_df = pd.DataFrame({
        'Word': words,
        'Penalty': word_penalties,
        'Unicode Representation': unicode_representations
    })
    result_df.to_excel("sentence_complexity_penalty.xlsx", index=False)

    return word_penalties


def count_high_penalty_words(sentence, threshold, penalty_type):
    word_penalties = calculate_sentence_penalty(sentence, penalty_type)
    return sum(p > threshold for p in word_penalties)


# Example usage
sentence = "à¤¹à¤®à¤¾à¤°à¥‡ à¤µà¥ˆà¤œà¥à¤žà¤¾à¤¨à¤¿à¤•à¥‹à¤‚ à¤¨à¥‡ à¤šà¤‚à¤¦à¥à¤°à¤¯à¤¾à¤¨-3 à¤•à¥‹ à¤šà¤¾à¤à¤¦ à¤•à¥‡ à¤¦à¤•à¥à¤·à¤¿à¤£à¥€ à¤§à¥à¤°à¥à¤µ à¤ªà¤° à¤‰à¤¤à¤¾à¤°à¤¾ à¤¹à¥ˆ"
count = count_high_penalty_words(sentence,10,"all")
print("Number of high-penalty words:", count)
print(calculate_sentence_penalty("à¤¹à¤®à¤¾à¤°à¥‡ à¤µà¥ˆà¤œà¥à¤žà¤¾à¤¨à¤¿à¤•à¥‹à¤‚ à¤¨à¥‡ à¤šà¤‚à¤¦à¥à¤°à¤¯à¤¾à¤¨-3 à¤•à¥‹ à¤šà¤¾à¤à¤¦ à¤•à¥‡ à¤¦à¤•à¥à¤·à¤¿à¤£à¥€ à¤§à¥à¤°à¥à¤µ à¤ªà¤° à¤‰à¤¤à¤¾à¤°à¤¾ à¤¹à¥ˆ","all"))

def average_word_length(sentence):
    """
    Calculates the average word length for a given sentence.

    Parameters:
    sentence (str): The sentence to calculate the average word length for.

    Returns:
    float: The average word length of the sentence.
    """
    words = sentence.split()
    return sum(len(word) for word in words) / len(words) if words else 0

def compute_ttr_hindi(text: str) -> float:
    """
    Compute Type-Token Ratio (TTR) for a Hindi sentence or text.

    Args:
        text (str): Input Hindi sentence or text.

    Returns:
        float: Type-Token Ratio (0 to 1)
    """
    # Lowercase for uniformity (useful if text has mixed case)
    text = text.lower()

    # Remove punctuation and digits (optional but recommended)
    text = re.sub(r"[^\u0900-\u097F\s]", "", text)

    # Split into words (tokens)
    tokens = text.split()
    if not tokens:
        return 0.0

    # Count unique words (types)
    types = set(tokens)
    # print(len(types))
    # print(len(tokens))
    # Compute TTR
    return len(types) / len(tokens)


# ðŸ“ Example
sentence = "à¤¹à¤®à¤¾à¤°à¥‡ à¤µà¥ˆà¤œà¥à¤žà¤¾à¤¨à¤¿à¤•à¥‹à¤‚ à¤¨à¥‡ à¤šà¤‚à¤¦à¥à¤°à¤¯à¤¾à¤¨ à¤•à¥‹ à¤šà¤¾à¤à¤¦ à¤ªà¤° à¤‰à¤¤à¤¾à¤°à¤¾à¥¤ à¤šà¤‚à¤¦à¥à¤°à¤¯à¤¾à¤¨ à¤¸à¤«à¤² à¤°à¤¹à¤¾à¥¤"
ttr_value = compute_ttr_hindi(sentence)
print(f"TTR: {ttr_value:.4f}")

# Regex pattern to match common Hindi matras (dependent vowel signs)
MATRA_PATTERN = re.compile(r'[\u093E\u093F\u0940\u0941\u0942\u0943\u0944\u0945\u0947\u0948\u0949\u094B\u094C]')

def average_matras_per_word(sentence: str) -> float:
    # Split the sentence into words
    words = [w for w in sentence.strip().split() if w]
    if not words:
        return 0.0

    # Count matras in each word
    total_matras = 0
    for word in words:
        total_matras += len(MATRA_PATTERN.findall(word))

    # Calculate average
    return total_matras / len(words)


# ðŸ”¹ Example usage
hindi_sentence = "à¤µà¤¿à¤¦à¥à¤¯à¤¾à¤²à¤¯ à¤®à¥‡à¤‚ à¤¬à¤šà¥à¤šà¥‡ à¤ªà¤¢à¤¼à¤¾à¤ˆ à¤•à¤°à¤¤à¥‡ à¤¹à¥ˆà¤‚à¥¤"
avg = average_matras_per_word(hindi_sentence)
print("Average matras per word:", avg)

def extract_features(sentences):
    """
    Extract features for each sentence.

    Features:
    - Average word penalty
    - Average word length
    - Total sentence length (in characters)
    - Total penalty of a sentence

    Args:
        sentences (list of str): List of sentences.

    Returns:
        np.ndarray: Array of feature vectors.
    """
    features = []
    for sentence in sentences:
        words = sentence.split()

        # avg_word_penalty_all = calculate_avg_sentence_penalty(sentence,"all")
        # avg_word_penalty_equal = calculate_avg_sentence_penalty(sentence,"equal")
        # avg_word_penalty_unequal = calculate_avg_sentence_penalty(sentence,"unequal")
        # complex_words_all = count_high_penalty_words(sentence,15,"all")
        # complex_words_equal = count_high_penalty_words(sentence,15,"equal")
        complex_words = count_high_penalty_words(sentence,15,"unequal")
        avg_word_length = np.mean([len(word) for word in words]) if words else 0
        total_length = len(words)
        ttr=compute_ttr_hindi(sentence)
        avg_matra=average_matras_per_word(sentence)
        # total_penalty_all = calculate_sentence_penalty_og(sentence,"all")
        # total_penalty_equal = calculate_sentence_penalty_og(sentence,"equal")
        # total_penalty_unequal = calculate_sentence_penalty_og(sentence,"unequal")
        ja=0
        # prob = 0
        for word in words:
          # if word in word_dict:
          #   # prob+=word_dict[word]
          # else:
          #   # prob+=1
          ja+=count_jukta_akshar(word)
        # syn_complex=get_syn_complex(sentence)

        # llm_score=get_readability_score(sentence)
        # Append a single feature vector for each sentence
        features.append([complex_words, avg_word_length, total_length,avg_matra,ja/len(words),ttr])
        # features.append([avg_word_penalty_all,avg_word_penalty_equal,avg_word_penalty_unequal, complex_words_all,complex_words_equal, complex_words_unequal,avg_word_length, total_length,ja/len(words),ja,ttr,avg_matra,total_penalty_all,total_penalty_equal,total_penalty_unequal])

        # print(features)
    # Convert to NumPy array for consistent shape
    return np.array(features)

from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import StratifiedKFold
from sklearn.preprocessing import KBinsDiscretizer

def train_linear_regression_model(sentences, ground_truth, n_splits=5):
    """
    Trains a linear regression model using stratified 5-fold cross-validation.

    Args:
        sentences (list of str): List of sentences.
        ground_truth (list of float): Ground truth continuous scores.
        n_splits (int): Number of cross-validation splits. Default is 5.

    Returns:
        model: LinearRegression model trained on the full data.
    """
    # Extract features from sentences
    features = extract_features(sentences)
    ground_truth = np.array(ground_truth)

    # Bin targets for stratification
    binned_labels = KBinsDiscretizer(n_bins=n_splits, encode='ordinal', strategy='quantile') \
                        .fit_transform(ground_truth.reshape(-1, 1)).ravel()

    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)
    mse_scores = []
    r2_scores = []

    for fold, (train_idx, test_idx) in enumerate(skf.split(features, binned_labels), 1):
        X_train, X_test = features[train_idx], features[test_idx]
        y_train, y_test = ground_truth[train_idx], ground_truth[test_idx]

        model = LinearRegression()
        model.fit(X_train, y_train)
        predictions = model.predict(X_test)

        mse = mean_squared_error(y_test, predictions)
        r2 = r2_score(y_test, predictions)

        mse_scores.append(mse)
        r2_scores.append(r2)

        print(f"Fold {fold} MSE: {mse:.4f}, RÂ²: {r2:.4f}")

    print(f"\nAverage MSE across {n_splits} folds: {np.mean(mse_scores):.4f}")
    print(f"Average RÂ² across {n_splits} folds: {np.mean(r2_scores):.4f}")

    # Train final model on full data
    model.fit(features, ground_truth)

    # Show final model coefficients
    coefficients = model.coef_
    intercept = model.intercept_

    print("\nFinal Model Coefficients (trained on full data):")
    print(f"Average Word Penalty Coefficient: {coefficients[0]:.4f}")
    print(f"Average Word Length Coefficient: {coefficients[1]:.4f}")
    print(f"Total Sentence Length Coefficient: {coefficients[2]:.4f}")
    print(f"Matra Coefficient: {coefficients[3]:.4f}")
    print(f"JA coefficient: {coefficients[4]:.4f}")
    print(f"TTR coefficient: {coefficients[5]:.4f}")
    # print(f"TTR coefficient: {coefficients[3]:.4f}")
    # print(f"Syntactic Complexity Term: {coefficients[7]:.4f}")

    print(f"Bias (Intercept) Term: {intercept:.4f}")

    # Evaluate final model on full training set
    predictions = model.predict(features)
    mse = mean_squared_error(ground_truth, predictions)
    r2 = r2_score(ground_truth, predictions)
    print(f"\nFinal Model MSE on Full Data: {mse:.4f}")
    print(f"Final Model RÂ² on Full Data: {r2:.4f}")

    return model
sentences = [
    "à¤®à¥à¤à¥‡ 1 à¤ªà¥à¤°à¥‹à¤—à¥à¤°à¤¾à¤®à¤¿à¤‚à¤— à¤ªà¤¸à¤‚à¤¦ à¤¹à¥ˆà¥¤",
    "à¤®à¥à¤à¥‡ 1 à¤ªà¥à¤°à¥‹à¤—à¥à¤°à¤¾à¤®à¤¿à¤‚à¤— à¤ªà¤¸à¤‚à¤¦ à¤¹à¥ˆà¥¤",
    "à¤®à¥à¤à¥‡ 1 à¤ªà¥à¤°à¥‹à¤—à¥à¤°à¤¾à¤®à¤¿à¤‚à¤— à¤ªà¤¸à¤‚à¤¦ à¤¹à¥ˆà¥¤",
    "à¤®à¥à¤à¥‡ 1 à¤ªà¥à¤°à¥‹à¤—à¥à¤°à¤¾à¤®à¤¿à¤‚à¤— à¤ªà¤¸à¤‚à¤¦ à¤¹à¥ˆà¥¤",
    "à¤®à¥à¤à¥‡ 1 à¤ªà¥à¤°à¥‹à¤—à¥à¤°à¤¾à¤®à¤¿à¤‚à¤— à¤ªà¤¸à¤‚à¤¦ à¤¹à¥ˆà¥¤",
    "à¤®à¥à¤à¥‡ 1 à¤ªà¥à¤°à¥‹à¤—à¥à¤°à¤¾à¤®à¤¿à¤‚à¤— à¤ªà¤¸à¤‚à¤¦ à¤¹à¥ˆà¥¤",
    "à¤®à¥à¤à¥‡ 1 à¤ªà¥à¤°à¥‹à¤—à¥à¤°à¤¾à¤®à¤¿à¤‚à¤— à¤ªà¤¸à¤‚à¤¦ à¤¹à¥ˆà¥¤",
    "à¤®à¥à¤à¥‡ 1 à¤ªà¥à¤°à¥‹à¤—à¥à¤°à¤¾à¤®à¤¿à¤‚à¤— à¤ªà¤¸à¤‚à¤¦ à¤¹à¥ˆà¥¤"
]

ground_truth = [6, 6,6,6,6,6,6,6]  # Example ground truth scores

# # Train the model
model = train_linear_regression_model(sentences, ground_truth)

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

def train_linear_classification_model(sentences, labels):
    """
    Trains a logistic regression model to classify sentences into categories from 1 to 6.

    Args:
        sentences (list of str): List of sentences.
        labels (list of int): List of integer labels (1 to 6) for the sentences.

    Returns:
        model: Trained LogisticRegression model.
    """
    # Extract features from sentences
    features = extract_features(sentences)

    # Train the logistic regression model
    model = LogisticRegression(max_iter=1000, multi_class='multinomial', solver='lbfgs')
    model.fit(features, labels)

    # Get coefficients for each feature
    coefficients = model.coef_
    intercept = model.intercept_

    print("Feature Coefficients:")
    for i, coef in enumerate(coefficients.T):
        print(f"Feature {i+1} Coefficients: {coef}")
    print(f"Bias (Intercept) Terms: {intercept}")

    # Evaluate the model
    predictions = model.predict(features)
    accuracy = accuracy_score(labels, predictions)
    print(f"\nAccuracy on Training Data: {accuracy:.4f}")

    return model

def train_test_split_lists(list1, list2, test_size=0.2, random_state=42):
    """
    Splits two lists into training and testing subsets while maintaining correspondence.

    Parameters:
    - list1: First list of data (e.g., features).
    - list2: Second list of data (e.g., labels).
    - test_size: Fraction of data to reserve for testing (default is 20%).
    - random_state: Seed for reproducibility.

    Returns:
    - train_list1, test_list1: Training and testing subsets of list1.
    - train_list2, test_list2: Training and testing subsets of list2.
    """
    if len(list1) != len(list2):
        raise ValueError("Both lists must have the same length.")

    # Set random seed for reproducibility if specified
    if random_state is not None:
        random.seed(random_state)

    # Generate shuffled indices
    indices = list(range(len(list1)))
    random.shuffle(indices)

    # Split indices into train and test
    split_index = int(len(list1) * (1 - test_size))
    train_indices = indices[:split_index]
    test_indices = indices[split_index:]

    # Use indices to split the lists
    train_list1 = [list1[i] for i in train_indices]
    test_list1 = [list1[i] for i in test_indices]
    train_list2 = [list2[i] for i in train_indices]
    test_list2 = [list2[i] for i in test_indices]

    return train_list1, test_list1, train_list2, test_list2

# Example usage:
# Input data testing sets
# train_features, test_features, train_labels, test_labels = train_test_split_lists(features, labels, test_size=0.2, random_state=42)

# # Train a linear regression model (example)
# model = train_linear_regression_model
# model.fit(train_features, train_labels)

# # Evaluate the model
# predictions = model.predict(test_features)
# mse = mean_squared_error(test_labels, predictions)

# # Output results
# print("Train Features:", train_features)
# print("Test Features:", test_features)
# print("Train Labels:", train_labels)
# print("Test Labels:", test_labels)
# print("Mean Squared Error:", mse)

# Function to test the model
def test_model(model, x_test, y_test):
    """
    Tests the trained model on the test dataset.

    Args:
        model: Trained LinearRegression model.
        x_test (list of str): List of test sentences.
        y_test (list of float): Ground truth scores for the test sentences.

    Returns:
        None
    """
    # Extract features from test sentences
    x_test_features = extract_features(x_test)

    # Make predictions on the test set
    predictions = model.predict(x_test_features)

    # Evaluate the model
    rmse = mean_squared_error(y_test, predictions, squared=False)  # Changed to RMSE
    r2 = r2_score(y_test, predictions)

    # Print evaluation metrics
    print("Model Evaluation on Test Data:")
    print(f"Root Mean Squared Error (RMSE): {rmse:.4f}")
    print(f"R-squared (RÂ²): {r2:.4f}")

def predict_and_plot_with_boxplot(model, sentences, values):
    """
    Predicts the scores for a list of sentences using the trained model,
    plots the predicted values alongside a given array in a line plot,
    and shows a box plot for both predictions and the provided values.
    """

    # Extract features from the input sentences
    features = extract_features(sentences)  # Assuming `extract_features` is defined

    # Predict scores
    predictions = model.predict(features)

    # Plot the predictions and additional values: Line plot
    plt.figure(figsize=(14, 6))

    # Line plot
    plt.subplot(1, 2, 1)
    plt.plot(range(len(sentences)), predictions, marker='o', linestyle='-',
             color='b', label="Predicted Scores")
    plt.plot(range(len(sentences)), values, marker='s', linestyle='--',
             color='r', label="Target Values")

    plt.xlabel("Sentence Index", fontsize=14)
    plt.ylabel("Score", fontsize=14)
    plt.title("Predicted Scores vs Target Values", fontsize=16)
    plt.legend(fontsize=12)
    plt.xticks(fontsize=12)
    plt.yticks(fontsize=12)
    plt.grid(True)

    # Box plot
    plt.subplot(1, 2, 2)
    plt.boxplot([predictions, values], patch_artist=True,
                boxprops=dict(facecolor='lightblue', color='blue'))
    plt.xticks([1, 2], ["Predictions", "Target Levels"], fontsize=12)
    plt.ylabel("Scores", fontsize=14)
    plt.title("Box Plot of Predicted Scores and Target Values", fontsize=16)
    plt.yticks(fontsize=12)
    plt.grid(axis='y')

    # Adjust layout
    plt.tight_layout()
    plt.show()

    # Print mean values
    print(f"Mean of Predicted Scores: {np.mean(predictions):.2f}")
    print(f"Mean of TARGET Values: {np.mean(values):.2f}")

# import pandas as pd

# # Load the Excel file
# file_path = "combined_file.xlsx"  # Replace with your actual file path
# df = pd.read_excel(file_path)

# # Filter rows where 'Sub-domain' is 'Children Stories'
# filtered_df = df[df['Sub-domain'] == 'Children Stories']

# # Extract 'Sentences' and 'Rating' columns into lists
# sentences_cs = filtered_df['Sentence'].tolist()
# ratings_cs = filtered_df['Rating'].tolist()

# # Print or use the lists as needed
# # print(sentences)
# # print(ratings)

# import numpy as np
# import pandas as pd
# from sklearn.linear_model import LinearRegression
# from sklearn.metrics import mean_squared_error, r2_score
# import random
# import math
# def extract_features(sentences):
#     """
#     Extract features for each sentence.

#     Features:
#     - Average word penalty
#     - Average word length
#     - Total sentence length (in characters)
#     - Total penalty of a sentence

#     Args:
#         sentences (list of str): List of sentences.

#     Returns:
#         np.ndarray: Array of feature vectors.
#     """
#     features = []
#     for sentence in sentences:
#         words = sentence.split()

#         avg_word_penalty = calculate_avg_sentence_penalty(sentence)
#         avg_word_length = np.mean([len(word) for word in words]) if words else 0
#         total_length = len(words)
#         total_length_char=len(sentence)
#         total_penalty = calculate_sentence_penalty(sentence)
#         ja=0
#         prob = 0
#         for word in words:
#           if word in word_dict:
#             prob+=word_dict[word]
#           else:
#             prob+=1
#           ja+=count_jukta_akshar(word)
#         syn_complex=get_syn_complex(sentence)

#         # llm_score=get_readability_score(sentence)
#         # Append a single feature vector for each sentence
#         features.append([avg_word_penalty, avg_word_length, total_length,total_length_char,total_penalty,prob, ja,ja/len(words),syn_complex])
#         # print(features)
#     # Convert to NumPy array for consistent shape
#     return np.array(features)

sen=class1_story+class2_story+class3_story+class4_story+class5_story+class6_story+class7_story+class8_story
seno=ratingc1s+ratingc2s+ratingc3s+ratingc4s+ratingc5s+ratingc6s+ratingc7s+ratingc8s
x_train, x_test, y_train, y_test=train_test_split_lists(sen,seno)

import matplotlib.pyplot as plt
import numpy as np
from collections import Counter

# Replace with your own lists
lists = [
    ratingc1s,
    ratingc2s,
    ratingc3s,
    ratingc4s,
    ratingc5s,
    ratingc6s,
    ratingc7s,
    ratingc8s
]

num_grades = len(lists)
levels = range(1, 7)  # readability levels 1â€“6
freq_matrix = np.zeros((len(levels), num_grades), dtype=int)
perc_matrix = np.zeros((len(levels), num_grades), dtype=float)

# Build frequency & percentage matrices
for j, grade_list in enumerate(lists):
    counts = Counter(grade_list)
    total = len(grade_list)
    for i, lvl in enumerate(levels):
        freq_matrix[i, j] = counts[lvl]
        perc_matrix[i, j] = (counts[lvl] / total * 100) if total > 0 else 0  # store as percentage

plt.figure(figsize=(10, 6))
im = plt.imshow(perc_matrix, cmap="YlOrRd", aspect="auto", origin="lower")

# Add labels
plt.xticks(range(num_grades), [f"Grade {i+1}" for i in range(num_grades)])
plt.yticks(range(len(levels)), levels)
plt.colorbar(im, label="Percentage (%)")

plt.ylabel("Readability Level")
plt.xlabel("Grade")
plt.title("Readability Level Distribution across Grades")

# Annotate cells with frequency and percentage (2 decimal places)
for i in range(len(levels)):
    for j in range(num_grades):
        freq = freq_matrix[i, j]
        perc = perc_matrix[i, j]
        if freq > 0:
            plt.text(j, i, f"{freq}\n({perc:.2f}%)",
                     ha="center", va="center", color="black", fontsize=9)

plt.show()

import matplotlib.pyplot as plt

# lists = [ratingc1s, ratingc2s, ..., ratingc8s]  # your data

plt.figure(figsize=(10, 6))

parts = plt.violinplot(lists, showmeans=False, showextrema=False, showmedians=False)

# Customize colors (optional)
for pc in parts['bodies']:
    pc.set_facecolor("#FF9933")  # orange
    pc.set_edgecolor("black")
    pc.set_alpha(0.7)

# Increase font size
plt.xticks(range(1, len(lists)+1),
           [f"{i+1}" for i in range(len(lists))],
           fontsize=18)
plt.yticks(range(1, 7), fontsize=18)

plt.xlabel("Grade", fontsize=20)
plt.ylabel("Readability Level", fontsize=20)
plt.title("Readability Level Distribution across Grades", fontsize=22)

plt.show()

# Count words across all sentences
total_words = sum(len(s.split()) for s in class8_story)

print("Total number of words:", total_words)

values=extract_features(sen)

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from statsmodels.stats.outliers_influence import variance_inflation_factor
import statsmodels.api as sm

# X_array = extract_features(sentences)

# Give proper feature names
feature_names = ['complex_words', 'avg_word_length', 'total_length', 'avg_matra', 'ja_per_word', 'ttr']

# Convert to DataFrame
X_df = pd.DataFrame(values, columns=feature_names)

# -----------------------------
# 1. Correlation matrix
# -----------------------------
corr_matrix = X_df.corr()
print("Correlation Matrix:\n", corr_matrix)

# Optional: visualize
plt.figure(figsize=(8,6))
sns.heatmap(corr_matrix, annot=True, fmt=".2f", cmap='coolwarm')
plt.title("Feature Correlation (Collinearity) Matrix")
plt.show()

# -----------------------------
# 2. Variance Inflation Factor (VIF)
# -----------------------------
X_with_const = sm.add_constant(X_df)  # add intercept

vif_data = pd.DataFrame()
vif_data["Feature"] = X_with_const.columns
vif_data["VIF"] = [variance_inflation_factor(X_with_const.values, i)
                   for i in range(X_with_const.shape[1])]

print("\nVariance Inflation Factor (VIF) for each feature:\n", vif_data)

# # Create DataFrame with fixed column names
# df = pd.DataFrame(values, columns=["Average Word Penalty(all)","Average Word Penalty(equal)","Average Word Penalty(unequal)","Number of Complex Words(all)","Number of Complex Words(equal)","Number of Complex Words(unequal", "Average Number of Characters per Word", "Total Sentence Length(in words)","Average Jukta Akshars per Word","Total Jukta Akshars","Type-Token Ratio","Average Matras per Word","Total Sentence Penalty(all)","Total Sentence Penalty(equal)","Total Sentence Penalty(unequal)"])
# df.insert(0, "Sentence", sen)
# df["Readability Level"] = seno

# # Save to Excel without renaming columns
# df.to_excel("output.xlsx", index=False)

# print("Excel file saved as 'output.xlsx'.")

import matplotlib.pyplot as plt
import numpy as np

def plot_array(data):
    plt.figure(figsize=(10, 5))
    plt.plot(data, marker='o', linestyle='-', color='b', label='Data Points')
    plt.xlabel("Index")
    plt.ylabel("Value")
    plt.title("Array Plot")
    plt.legend()
    plt.grid(True)
    plt.show()

# Example Usage

import matplotlib.pyplot as plt
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

# Function to train and evaluate a Random Forest Regressor
def train_random_forest(X, y):
    X=extract_features(X)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    model = RandomForestRegressor(n_estimators=100, random_state=42)
    model.fit(X_train, y_train)
    predictions = model.predict(X_test)
    mse = mean_squared_error(y_test, predictions,squared=False)
    print(f"Mean Squared Error: {mse}")
    return model

from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import mean_squared_error, accuracy_score
from sklearn.preprocessing import LabelEncoder, KBinsDiscretizer
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import KBinsDiscretizer

def train_random_forest_regression(X, y, n_splits=5):
    """
    Train a Random Forest Regressor using Stratified K-Fold Cross-Validation.

    Args:
        X (list of str): List of input sentences (features).
        y (list of float): Continuous target values.
        n_splits (int): Number of cross-validation splits.

    Returns:
        model (RandomForestRegressor): Trained model on full data.
    """
    X = extract_features(X)  # Convert text data into features
    y = np.array(y)

    # Bin continuous target values for stratified splitting
    y_binned = KBinsDiscretizer(n_bins=n_splits, encode='ordinal', strategy='quantile') \
                    .fit_transform(y.reshape(-1, 1)).ravel()

    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)

    rmse_scores = []
    r2_scores = []

    for fold, (train_idx, test_idx) in enumerate(skf.split(X, y_binned), 1):
        X_train, X_test = X[train_idx], X[test_idx]
        y_train, y_test = y[train_idx], y[test_idx]

        model = RandomForestRegressor(n_estimators=100, random_state=42)
        model.fit(X_train, y_train)
        predictions = model.predict(X_test)

        rmse = np.sqrt(mean_squared_error(y_test, predictions))
        r2 = r2_score(y_test, predictions)

        rmse_scores.append(rmse)
        r2_scores.append(r2)

        print(f"Fold {fold} RMSE: {rmse:.4f}, RÂ²: {r2:.4f}")

    print(f"\nAverage RMSE across {n_splits} folds: {np.mean(rmse_scores):.4f}")
    print(f"Average RÂ² across {n_splits} folds: {np.mean(r2_scores):.4f}")

    # Train final model on all data
    model.fit(X, y)
    final_predictions = model.predict(X)
    final_rmse = np.sqrt(mean_squared_error(y, final_predictions))
    final_r2 = r2_score(y, final_predictions)

    print(f"\nFinal Model RMSE on Full Data: {final_rmse:.4f}")
    print(f"Final Model RÂ² on Full Data: {final_r2:.4f}")

    return model

def train_random_forest_classification(X, y, n_splits=5):
    """
    Train a Random Forest Classifier using Stratified K-Fold Cross-Validation.

    Args:
        X (list of str): List of input sentences (features).
        y (list of int or str): Target class labels.
        n_splits (int): Number of cross-validation splits.

    Returns:
        model (RandomForestClassifier): Trained model.
    """
    X = extract_features(X)  # Convert text data into features
    y = LabelEncoder().fit_transform(y)  # Encode categorical labels

    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)

    accuracy_scores = []

    for train_idx, test_idx in skf.split(X, y):  # Directly use labels for stratification
        X_train, X_test = X[train_idx], X[test_idx]
        y_train, y_test = y[train_idx], y[test_idx]

        model = RandomForestClassifier(n_estimators=100, random_state=42)
        model.fit(X_train, y_train)
        predictions = model.predict(X_test)

        acc = accuracy_score(y_test, predictions)  # Compute accuracy
        accuracy_scores.append(acc)

    print(f"Average Accuracy: {np.mean(accuracy_scores) * 100:.2f}%")
    return model

import numpy as np
import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
import random
import math
def extract_features(sentences):
    """
    Extract features for each sentence.

    Features:
    - Average word penalty
    - Average word length
    - Total sentence length (in characters)
    - Total penalty of a sentence

    Args:
        sentences (list of str): List of sentences.

    Returns:
        np.ndarray: Array of feature vectors.
    """
    features = []
    for sentence in sentences:
        words = sentence.split()

        # avg_word_penalty_all = calculate_avg_sentence_penalty(sentence,"all")
        # avg_word_penalty_equal = calculate_avg_sentence_penalty(sentence,"equal")
        # avg_word_penalty_unequal = calculate_avg_sentence_penalty(sentence,"unequal")
        # complex_words_all = count_high_penalty_words(sentence,15,"all")
        # complex_words_equal = count_high_penalty_words(sentence,15,"equal")
        complex_words = count_high_penalty_words(sentence,30,"unequal")
        avg_word_length = np.mean([len(word) for word in words]) if words else 0
        total_length = len(words)
        ttr=compute_ttr_hindi(sentence)
        avg_matra=average_matras_per_word(sentence)
        # total_penalty_all = calculate_sentence_penalty_og(sentence,"all")
        # total_penalty_equal = calculate_sentence_penalty_og(sentence,"equal")
        # total_penalty_unequal = calculate_sentence_penalty_og(sentence,"unequal")
        ja=0
        # prob = 0
        for word in words:
          # if word in word_dict:
          #   # prob+=word_dict[word]
          # else:
          #   # prob+=1
          ja+=count_jukta_akshar(word)
        # syn_complex=get_syn_complex(sentence)

        # llm_score=get_readability_score(sentence)
        # Append a single feature vector for each sentence
        features.append([complex_words, avg_word_length, total_length,avg_matra,ja/len(words),ttr])
        # features.append([avg_word_penalty_all,avg_word_penalty_equal,avg_word_penalty_unequal, complex_words_all,complex_words_equal, complex_words_unequal,avg_word_length, total_length,ja/len(words),ja,ttr,avg_matra,total_penalty_all,total_penalty_equal,total_penalty_unequal])

        # print(features)
    # Convert to NumPy array for consistent shape
    return np.array(features)

model=train_linear_regression_model(sen,seno)

import statsmodels.api as sm
import pandas as pd

# Assume: X_train is your feature DataFrame and y_train is the target Series
# Step 1: Add intercept term
X_train=extract_features(sen)
X_with_const = sm.add_constant(X_train)

# Step 2: Fit OLS model using statsmodels
ols_model = sm.OLS(seno, X_with_const).fit()

# Step 3: Get p-values
p_values = ols_model.pvalues

# Display p-values
print("P-values for each feature:\n")
print(p_values)

t_values=ols_model.tvalues
print(t_values)

# rf = train_random_forest_regression(sen,seno)

# #trained on ncert and run on ncert

# X_test=extract_features(x_test)
# X_test = scaler.transform(X_test)

# y_pred = svr.predict(X_test)

# # Evaluate performance
# mse = mean_squared_error(y_test, y_pred)
# print(f"Mean Squared Error: {mse}")

# test_model(rf,sen_readme,seno_readme)

import matplotlib.pyplot as plt
from collections import Counter

def plot_frequency_distribution(integer_list):
    """
    Plots the frequency distribution of integers in the given list and prints the frequency values.

    Args:
        integer_list (list): List of integers to plot and print.
    """
    # Calculate the frequency of each integer using Counter
    frequency = Counter(integer_list)

    # Print the frequency values
    print("Frequency of each integer value:")
    for value, count in frequency.items():
        print(f"Value {value}: {count} occurrences")

    # Plot the frequency distribution
    plt.figure(figsize=(8, 6))
    plt.bar(frequency.keys(), frequency.values(), color='blue')

    # Add labels and title to the chart
    plt.title('Frequency Distribution of Text according to Readability', fontsize=16)
    plt.xlabel('Readability Level ', fontsize=12)
    plt.ylabel('Frequency', fontsize=12)
    plt.xticks(range(min(frequency.keys()), max(frequency.keys()) + 1))  # Ensure the x-axis shows all integer values

    # Display the bar chart
    plt.tight_layout()
    plt.show()

plot_frequency_distribution(ratingc7s)

plot_frequency_distribution(ratingc6s)

plot_frequency_distribution(ratingc5s)

plot_frequency_distribution(ratingc4s)

plot_frequency_distribution(ratingc3s)

plot_frequency_distribution(ratingc2s)

plot_frequency_distribution(ratingc1s)

predict_and_plot_with_boxplot(model, class1_story,ratingc1s)

predict_and_plot_with_boxplot(model, class2_story,ratingc2s)

predict_and_plot_with_boxplot(model, class3_story,ratingc3s)

predict_and_plot_with_boxplot(model, class4_story,ratingc4s)

predict_and_plot_with_boxplot(model, class5_story,ratingc5s)

predict_and_plot_with_boxplot(model, class6_story,ratingc6s)

predict_and_plot_with_boxplot(model, class7_story,ratingc7s)

predict_and_plot_with_boxplot(model, class8_story,ratingc8s)

# predict_and_plot_with_boxplot(model, class4_story)

# predict_and_plot_with_boxplot(rf, class4_story)

# predict_and_plot_with_boxplot(rf, class4_story,ratingc4s)

# predict_and_plot_with_boxplot(rf, class5_story,ratingc5s)

# predict_and_plot_with_boxplot(rf, class6_story,ratingc6s)

# predict_and_plot_with_boxplot(rf, class7_story,ratingc7s)

# predict_and_plot_with_boxplot(rf, class8_story,ratingc8s)

# pip install lazypredict

# import lazypredict

# from lazypredict.Supervised import LazyClassifier

# X_train=extract_features(x_train)
# X_test=extract_features(x_test)

# clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)
# models,predictions = clf.fit(X_train, X_test, y_train, y_test)

# print(models)

# from lazypredict.Supervised import LazyRegressor
# from sklearn import datasets
# from sklearn.utils import shuffle
# import numpy as np
# reg = LazyRegressor(verbose=0, ignore_warnings=False, custom_metric=None)
# models, predictions = reg.fit(X_train, X_test, y_train, y_test)

# print(models)

# import pandas as pd
# from sklearn.feature_extraction.text import TfidfVectorizer


# # Convert to DataFrame with feature names
# X_train_df = pd.DataFrame(X_train)

# # Feature names are now available for plotting
# feature_names = X_train_df.columns.tolist()

# print(X_train_df.head())  # Check the transformed feature matrix
# print(len(X_train_df))

# import matplotlib.pyplot as plt
# import seaborn as sns
# import pandas as pd

# def plot_feature_importance(model, feature_names):
#     """
#     Plots feature importance for a trained Random Forest model.

#     Parameters:
#     - model: Trained RandomForest model (from sklearn)
#     - feature_names: List of feature names
#     """
#     # Extract feature importances
#     importances = model.feature_importances_

#     # Create a DataFrame for sorting and plotting
#     feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})
#     feature_importance_df = feature_importance_df.sort_values(by="Importance", ascending=False)

#     # Plot
#     plt.figure(figsize=(10, 6))
#     sns.barplot(y='Importance', x='Feature', data=feature_importance_df, palette="viridis")

#     plt.xlabel("Feature Importance Score")
#     plt.ylabel("Features")
#     plt.title("Feature Importance in Random Forest")
#     plt.show()

# # Example usage (assuming you have trained a RandomForest model)
# # from sklearn.ensemble import RandomForestClassifier
# # rf_model = RandomForestClassifier().fit(X_train, y_train)
# feature_names = X_train_df.columns.tolist()

# plot_feature_importance(rf, feature_names)

# import matplotlib.pyplot as plt
# import seaborn as sns
# import pandas as pd

# def plot_feature_importance(model, feature_names):
#     """
#     Plots feature importance for a trained Random Forest model with feature names on the x-axis.

#     Parameters:
#     - model: Trained RandomForest model (from sklearn)
#     - feature_names: List of feature names
#     """
#     # Extract feature importances
#     importances = model.feature_importances_

#     # Create a DataFrame for sorting and plotting
#     feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})
#     feature_importance_df = feature_importance_df.sort_values(by="Importance", ascending=False)

#     # Set style for publication
#     sns.set(style="whitegrid", context="talk", font_scale=1.2)  # 'talk' or 'paper' are good for research plots

#     # Plot
#     plt.figure(figsize=(14, 6))
#     barplot = sns.barplot(x='Feature', y='Importance', data=feature_importance_df, palette="viridis")

#     # Font and label formatting
#     barplot.set_xlabel("Features", fontsize=16, weight='bold')
#     barplot.set_ylabel("Feature Importance Score", fontsize=16, weight='bold')
#     barplot.set_title("Feature Importance in Random Forest", fontsize=18, weight='bold')
#     barplot.tick_params(axis='x', rotation=0, labelsize=12)
#     barplot.tick_params(axis='y', labelsize=12)

#     plt.tight_layout()
#     plt.show()


# # Example usage (assuming rf and X_train_df are defined)
# feature_names = X_train_df.columns.tolist()
# plot_feature_importance(rf, feature_names)

def deterministic_sample_per_label_combined(
    sents1, sents2, sents3, sents4, sents5, sents6, sents7, sents8,
    nums1, nums2, nums3, nums4, nums5, nums6, nums7, nums8
):
    """
    Combines 8 sentence lists and 8 label lists, and returns exactly 10 sentences for each label (1 to 6).

    Returns:
    - sampled_sentences: list of 60 sampled sentences
    - sampled_labels: corresponding list of 60 labels
    """
    # Step 1: Combine all sentences and labels
    all_sentences = sents1 + sents2 + sents3 + sents4 + sents5 + sents6 + sents7 + sents8
    all_labels = nums1 + nums2 + nums3 + nums4 + nums5 + nums6 + nums7 + nums8

    # Step 2: Collect 10 examples per label
    label_counter = {i: 0 for i in range(1, 7)}
    max_per_label = 10
    local_samples = {i: [] for i in range(1, 7)}

    for sentence, label in zip(all_sentences, all_labels):
        if label in label_counter and label_counter[label] < max_per_label:
            local_samples[label].append(sentence)
            label_counter[label] += 1
        if all(count == max_per_label for count in label_counter.values()):
            break

    # Step 3: Validate and prepare output
    sampled_sentences = []
    sampled_labels = []
    for label in range(1, 7):
        if label_counter[label] < max_per_label:
            raise ValueError(f"Not enough items for label {label}. Found {label_counter[label]}, need 10.")
        sampled_sentences.extend(local_samples[label])
        sampled_labels.extend([label] * max_per_label)

    return sampled_sentences, sampled_labels

plotx,ploty=deterministic_sample_per_label_combined(class1_story,class2_story,class3_story,class4_story,class5_story,class6_story,class7_story,class8_story,ratingc1s,ratingc2s,
                                 ratingc3s,ratingc4s,ratingc5s,ratingc6s,ratingc7s,ratingc8s)

def select_least_accurate_samples(
    sampled_sentences, sampled_labels, model_predictions
):
    """
    Selects the 5 least accurate samples for each label from the provided data.

    Args:
    - sampled_sentences: The list of 60 sentences sampled by deterministic_sample_per_label_combined.
    - sampled_labels: The corresponding list of 60 true labels.
    - model_predictions: The list of 60 predicted labels from the model.

    Returns:
    - least_accurate_sentences: list of 30 sentences (5 per label)
    - least_accurate_labels: corresponding list of 30 true labels
    - least_accurate_predictions: corresponding list of 30 predicted labels
    """
    if not (len(sampled_sentences) == len(sampled_labels) == len(model_predictions) == 60):
        raise ValueError("Input lists must have a length of 60.")

    # Step 1: Combine data points and calculate error
    data_points = []
    for i in range(60):
        true_label = sampled_labels[i]
        predicted_label = model_predictions[i]
        # Calculate a simple error metric. A larger value indicates higher error.
        error = abs(true_label - predicted_label)

        data_points.append({
            'sentence': sampled_sentences[i],
            'true_label': true_label,
            'predicted_label': predicted_label,
            'error': error
        })

    # Step 2: Group data points by true label
    grouped_by_label = {i: [] for i in range(1, 7)}
    for dp in data_points:
        grouped_by_label[dp['true_label']].append(dp)

    # Step 3: Sort each group by error in descending order and select the top 5
    least_accurate_sentences = []
    least_accurate_labels = []
    least_accurate_predictions = []

    for label in range(1, 7):
        # Sort by error in descending order
        sorted_samples = sorted(grouped_by_label[label], key=lambda x: x['error'], reverse=True)

        # Take the top 5
        top_5_least_accurate = sorted_samples[:5]

        # Append to the final lists
        for sample in top_5_least_accurate:
            least_accurate_sentences.append(sample['sentence'])
            least_accurate_labels.append(sample['true_label'])
            least_accurate_predictions.append(sample['predicted_label'])

    return least_accurate_sentences, least_accurate_labels, least_accurate_predictions

# predict_and_plot_with_boxplot(rf,plotx,ploty)

# predict_and_plot_with_boxplot(rf,plotx,ploty)

import matplotlib.pyplot as plt
import numpy as np

def predict_and_plot_with_boxplot(model, sentences, values):
    """
    Predicts the scores for a list of sentences using the trained model,
    plots the predicted values alongside a given array in a line plot,
    and shows a box plot for both predictions and the provided values.
    """

    # Extract features from the input sentences
    features = extract_features(sentences)  # Assuming `extract_features` is defined

    # Predict scores
    predictions = model.predict(features)

    # Plot the predictions and additional values: Line plot
    plt.figure(figsize=(14, 6))

    # Line plot
    plt.subplot(1, 2, 1)
    plt.plot(range(len(sentences)), predictions, marker='o', linestyle='-',
             color='b', label="MLRM Predicted Scores")
    plt.plot(range(len(sentences)), values, marker='s', linestyle='--',
             color='r', label="Target Labels")

    plt.xlabel("Sentence Index", fontsize=20)
    plt.ylabel("Readability Level", fontsize=20)
    plt.title("MLRM Predictions vs Target Labels", fontsize=22)
    plt.legend(fontsize=16)
    plt.xticks(fontsize=18)
    plt.yticks(fontsize=18)
    plt.grid(True)

    # Box plot
    plt.subplot(1, 2, 2)
    plt.boxplot([predictions, values], patch_artist=True,
                boxprops=dict(facecolor='lightblue', color='blue'))
    plt.xticks([1, 2], ["MLRM Predictions", "Target Levels"], fontsize=12)
    plt.ylabel("Scores", fontsize=14)
    plt.title("Box Plot of Predicted Scores and Target Values", fontsize=22)
    plt.yticks(fontsize=12)
    plt.grid(axis='y')

    # Adjust layout
    plt.tight_layout()
    plt.show()

    # Print mean values
    print(f"Mean of Predicted Scores: {np.mean(predictions):.2f}")
    print(f"Mean of TARGET Values: {np.mean(values):.2f}")

predict_and_plot_with_boxplot(model,plotx,ploty)

import pandas as pd

def predict_and_return(model, sentences, values):
    """
    Modified version of predict_and_plot_with_boxplot that returns predictions.
    """
    features = extract_features(sentences)  # assuming you have this function
    predictions = model.predict(features)

    # keep the plotting if you want
    predict_and_plot_with_boxplot(model, sentences, values)

    return predictions


def save_predictions_to_csv(sentences, labels, predictions, filename="results.csv"):
    """
    Saves sentences, predictions, and labels into a CSV file.
    """
    df = pd.DataFrame({
        "Sentence": sentences,
        "Prediction": predictions,
        "Label": labels
    })
    df.to_csv(filename, index=False, encoding="utf-8-sig")
    print(f"Results saved to {filename}")

# Step 1: Get 60 balanced samples
# sampled_sentences, sampled_labels = deterministic_sample_per_label_combined(
#     sents1, sents2, sents3, sents4, sents5, sents6, sents7, sents8,
#     nums1, nums2, nums3, nums4, nums5, nums6, nums7, nums8
# )

# Step 2: Predict with Linear Regression
predictions = predict_and_return(model, plotx, ploty)
# /content/story1-109.txt
# Step 3: Save results to CSV
save_predictions_to_csv(plotx, ploty, predictions, "/content/balanced_results.csv")

# Step 4: Get least accurate samples
least_sentences, least_labels, least_preds = select_least_accurate_samples(
    plotx, ploty, predictions
)

# Step 5: Save least accurate to another CSV
save_predictions_to_csv(least_sentences, least_labels, least_preds, "/content/least_accurate_results.csv")

# import matplotlib.pyplot as plt
# import seaborn as sns
# import pandas as pd

# def plot_feature_importance(model, feature_names, display_names=None):
#     """
#     Plots feature importance for a trained Random Forest model with feature names on the x-axis.

#     Parameters:
#     - model: Trained RandomForest model (from sklearn)
#     - feature_names: List of feature names used in the model
#     - display_names: Optional list of strings to use as x-axis labels instead of raw feature_names
#     """
#     importances = model.feature_importances_

#     if display_names:
#         if len(display_names) != len(feature_names):
#             raise ValueError("display_names and feature_names must be the same length.")
#         x_labels = display_names
#     else:
#         x_labels = feature_names

#     # Create a DataFrame for sorting and plotting
#     feature_importance_df = pd.DataFrame({
#         'Feature': feature_names,
#         'DisplayName': x_labels,
#         'Importance': importances
#     }).sort_values(by="Importance", ascending=False)

#     sns.set(style="whitegrid", context="talk", font_scale=1.2)

#     plt.figure(figsize=(14, 10))
#     barplot = sns.barplot(x='DisplayName', y='Importance', data=feature_importance_df, palette="viridis")

#     barplot.set_xlabel("Features", fontsize=16, weight='bold')
#     barplot.set_ylabel("Feature Importance Score", fontsize=16, weight='bold')
#     barplot.set_title("Feature Importance in Random Forest", fontsize=18, weight='bold')
#     barplot.tick_params(axis='x', rotation=45, labelsize=16)
#     barplot.tick_params(axis='y', labelsize=12)

#     plt.tight_layout()
#     plt.show()

def ablation_study_rmse(sentences, ground_truth, feature_names=None, n_splits=5):
    """
    Performs ablation study by training models with different subsets of features,
    and returns RMSE, RÂ², and Adjusted RÂ². Prints the full results.

    Args:
        sentences (list of str): Input sentences.
        ground_truth (list of float): Target values.
        feature_names (list of str): Names of features in order.
        n_splits (int): Number of CV folds.

    Returns:
        results_df (pd.DataFrame): Each row has the subset of features and its performance (RMSE, RÂ², AdjRÂ²)
    """
    from itertools import combinations
    import numpy as np
    import pandas as pd
    from sklearn.linear_model import LinearRegression
    from sklearn.metrics import mean_squared_error, r2_score
    from sklearn.model_selection import StratifiedKFold
    from sklearn.preprocessing import KBinsDiscretizer

    # Extract features once
    full_features = extract_features(sentences)
    n_features = full_features.shape[1]

    if feature_names is None:
        feature_names = [f"Feature_{i}" for i in range(n_features)]

    results = []

    # Try subsets of features: 1 feature, 2 features, ... all features
    for r in range(1, n_features + 1):
        for subset_idx in combinations(range(n_features), r):
            subset_features = full_features[:, subset_idx]
            subset_names = [feature_names[i] for i in subset_idx]

            # Stratified CV setup
            binned_labels = KBinsDiscretizer(n_bins=n_splits, encode='ordinal', strategy='quantile') \
                                .fit_transform(np.array(ground_truth).reshape(-1, 1)).ravel()

            skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)
            rmse_scores, r2_scores, adj_r2_scores = [], [], []

            for train_idx, test_idx in skf.split(subset_features, binned_labels):
                X_train, X_test = subset_features[train_idx], subset_features[test_idx]
                y_train, y_test = np.array(ground_truth)[train_idx], np.array(ground_truth)[test_idx]

                model = LinearRegression()
                model.fit(X_train, y_train)
                preds = model.predict(X_test)

                rmse_scores.append(np.sqrt(mean_squared_error(y_test, preds)))
                r2 = r2_score(y_test, preds)
                r2_scores.append(r2)

                n_test = len(y_test)
                p = subset_features.shape[1]
                adj_r2 = 1 - (1 - r2) * (n_test - 1) / (n_test - p - 1)
                adj_r2_scores.append(adj_r2)

            results.append({
                "Features": subset_names,
                "Avg_RMSE": np.mean(rmse_scores),
                "Avg_R2": np.mean(r2_scores),
                "Avg_AdjR2": np.mean(adj_r2_scores)
            })

    results_df = pd.DataFrame(results)

    # Print the full table
    pd.set_option('display.max_rows', None)  # Show all rows
    pd.set_option('display.max_colwidth', None)  # Show full feature list
    print(results_df)

    return results_df

